{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 GDG basra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "084u8u0DpBlo"
      },
      "source": [
        "# Prompting with an Apollo 11 transcript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnQ_LVlzIeXo"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7QvXQMrIhuZ"
      },
      "source": [
        "This notebook provides a quick example of how to prompt Gemini 1.5 Pro using a text file. In this case, you'll use a 400 page transcript from [Apollo 11](https://www.nasa.gov/history/alsj/a11/a11trans.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qLuL9m7KhvxR"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ATIbQM0NHhkj"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNvhBdoDFnTC"
      },
      "source": [
        "Download the transcript."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V4XeFdX1rxaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26cc0c14-1a46-41bf-d6ed-83fb10d68e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-17 16:16:43--  https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.215.207, 142.250.98.207, 173.194.217.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.215.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 847790 (828K) [text/plain]\n",
            "Saving to: ‘a11.txt’\n",
            "\n",
            "\ra11.txt               0%[                    ]       0  --.-KB/s               \ra11.txt             100%[===================>] 827.92K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-08-17 16:16:43 (131 MB/s) - ‘a11.txt’ saved [847790/847790]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/data/a11.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoiKgO2CswzA"
      },
      "source": [
        "Prepare it for use in a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_HzrDdp2Q1Cu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7c19089c-ee52-4bc7-99c0-e86f8dccd993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/mpsl0kc3tvh6\n"
          ]
        }
      ],
      "source": [
        "text_file_name = \"a11.txt\"\n",
        "print(f\"Uploading file...\")\n",
        "text_file = genai.upload_file(path=text_file_name)\n",
        "print(f\"Completed upload: {text_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPPOECHzsIGJ"
      },
      "source": [
        "## Generate Content\n",
        "\n",
        "After the file has been uploaded, you can make `GenerateContent` requests that reference the File API URI. Then you will ask the model to find a few lighthearted moments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9b1d2fe3ea31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "aad37cfe-8d55-4662-9034-475f40607d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are four lighthearted moments from the text:\n",
            "\n",
            "1. **\"Cecil B. deAldrin is standing by for instructions.\"** (Tape 1/8, Page 8)  This is a humorous reference to Buzz Aldrin's full name and a playful nod to the famous film director Cecil B. DeMille. It suggests a lighthearted atmosphere within the crew.\n",
            "\n",
            "2. **\"And tell Glenn Parker down at the Cape that he lucked out.\"** (Tape 1/6, Page 6)  This is a playful jab at Glenn Parker, possibly someone at the launch site, suggesting a friendly rivalry or a light-hearted banter between the crew and ground personnel.\n",
            "\n",
            "3. **\"Apollo 11 is ready to go ahead with the - extend the docking probe, and ready to go with the RCS hot fire when you're ready to monitor. Over.\"** (Tape 2/2, Page 10)  The Commander's matter-of-fact tone and the slightly drawn-out pause before \"extend the docking probe\" creates a humorous effect, as if he's taking a moment to consider the gravity of the task.\n",
            "\n",
            "4. **\"And, 11, for your information, the magnitude of midcourse correction number 1, if we burn, looks like about 17 feet per second. We're presently considering not burning it. This would make midcourse correction 2 tomorrow about 21.3. Over.\"** (Tape 4/3, Page 27)  The casual phrasing \"We're presently considering not burning it\" implies a nonchalant approach to the mission's crucial maneuvers, making it a lighthearted moment in the midst of serious work. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Find four lighthearted moments in this text file.\"\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash\")\n",
        "\n",
        "response = model.generate_content([prompt, text_file],\n",
        "                                  request_options={\"timeout\": 600})\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrPDYdQSKTg4"
      },
      "source": [
        "## Delete File\n",
        "\n",
        "Files are automatically deleted after 2 days or you can manually delete them using `files.delete()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4eO8ZXoKdZf"
      },
      "outputs": [],
      "source": [
        "genai.delete_file(text_file.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5oUCqb6IUnH"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "The File API accepts files under 2GB in size and can store up to 20GB of files per project. Learn more about the [File API](https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb) here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Apollo_11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}